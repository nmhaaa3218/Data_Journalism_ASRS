{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on coordinates, decide if location is convenient or inconvenient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_rename_columns(df):\n",
    "    long_list = [\"Longitude\", \"Lng\"]\n",
    "    for col_name in long_list:\n",
    "        if col_name in df.columns:\n",
    "            df.rename(columns={col_name: 'long'}, inplace=True)\n",
    "            break\n",
    "\n",
    "    lat_list = [\"Latitude\", \"Lat\"]\n",
    "    for col_name in lat_list:\n",
    "        if col_name in df.columns:\n",
    "            df.rename(columns={col_name: 'lat'}, inplace=True)\n",
    "            break\n",
    "\n",
    "    postcode_list = [\"Postcode\", \"POSTCODE\"]\n",
    "    for col_name in postcode_list:\n",
    "        if col_name in df.columns:\n",
    "            df.rename(columns={col_name: 'postcode'}, inplace=True)\n",
    "            break\n",
    "\n",
    "    price_list = [\"PRODUCT_PRICE\", \"Price\"]\n",
    "    for col_name in price_list:\n",
    "        if col_name in df.columns:\n",
    "            df.rename(columns={col_name: 'price'}, inplace=True)\n",
    "            break\n",
    "\n",
    "    if \"FuelCode\" in df.columns:\n",
    "        df.rename(columns={\"FuelCode\": 'fueltype'}, inplace=True)\n",
    "\n",
    "    brand_list = [\"BrandName\", \"BRAND_DESCRIPTION\"]\n",
    "    for col_name in brand_list:\n",
    "        if col_name in df.columns:\n",
    "            df.rename(columns={col_name: 'brand'}, inplace=True)\n",
    "            break\n",
    "\n",
    "    if \"PUBLISH_DATE\" in df.columns:\n",
    "        df.rename(columns={\"PUBLISH_DATE\": 'collection_date'}, inplace=True)\n",
    "\n",
    "    if \"Address\" in df.columns:\n",
    "        df.rename(columns={\"Address\": 'address'}, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def combine_csv(path):\n",
    "    # Get all csv files in the folder\n",
    "    all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "    # Create an empty list to add the dataframes to\n",
    "    df_list = []\n",
    "\n",
    "    # Loop through the list of filepaths & read each one into a df\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        df_list.append(df)\n",
    "\n",
    "    # Concatenate all dataframes in the list\n",
    "    combined_df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "    # Return the dataframe\n",
    "    return combined_df\n",
    "\n",
    "def extract_address(state_fuel):\n",
    "    address = state_fuel[[\"address\", \"lat\", \"long\"]].drop_duplicates()\n",
    "    return address\n",
    "\n",
    "\n",
    "def is_convenient(lat, long):\n",
    "    # check performance\n",
    "    #start_time = time.time()\n",
    "    \n",
    "    point = (lat, long)\n",
    "    # only include main road structures\n",
    "    tags = {'highway': ['motorway', 'trunk', 'primary']}\n",
    "\n",
    "    try:\n",
    "        # features_from_point to get features within 500 meters\n",
    "        features = ox.features_from_point(point, tags, dist=500)\n",
    "        \n",
    "        # check performance\n",
    "        #end_time = time.time()\n",
    "        #print(end_time - start_time)\n",
    "        \n",
    "        # if no features\n",
    "        if features is None or features.empty:\n",
    "            return False\n",
    "        # if exist features\n",
    "        else:\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        # handle features_from_point error\n",
    "        return False\n",
    "      \n",
    "\n",
    "def mutate_convenient(state_fuel):\n",
    "    address = extract_address(state_fuel)\n",
    "\n",
    "    # Check if convenient\n",
    "    address['convenient'] = address.apply(lambda row: is_convenient(row['lat'], row['long']), axis=1)\n",
    "\n",
    "    # Left join to original dataframe\n",
    "    state_fuel = pd.merge(state_fuel, address, on=['address', 'lat', 'long'], how='left')\n",
    "\n",
    "    return state_fuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nsw\n",
    "# nsw = combine_csv(\"D:/UOA WORK/Summer Research/Data_Journalism_ASRS/fuel-prices/nsw\")\n",
    "nt = combine_csv(\"D:/UOA WORK/Summer Research/Data_Journalism_ASRS/fuel-prices/nt\")\n",
    "qld = combine_csv(\"D:/UOA WORK/Summer Research/Data_Journalism_ASRS/fuel-prices/qld\")\n",
    "sa = combine_csv(\"D:/UOA WORK/Summer Research/Data_Journalism_ASRS/fuel-prices/sa\")\n",
    "tas = combine_csv(\"D:/UOA WORK/Summer Research/Data_Journalism_ASRS/fuel-prices/tas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename dataframe\n",
    "# nsw = auto_rename_columns(nsw)\n",
    "nt = auto_rename_columns(nt)\n",
    "qld = auto_rename_columns(qld)\n",
    "sa = auto_rename_columns(sa)\n",
    "tas = auto_rename_columns(tas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsw_address = extract_address(nsw)\n",
    "nt_address = extract_address(nt)\n",
    "qld_address = extract_address(qld)\n",
    "sa_address = extract_address(sa)\n",
    "tas_address = extract_address(tas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsw_address[\"convenient\"] = nsw_address.apply(lambda row: is_convenient(row[\"lat\"], row[\"long\"]), axis=1)\n",
    "nt_address[\"convenient\"] = nt_address.apply(lambda row: is_convenient(row[\"lat\"], row[\"long\"]), axis=1)\n",
    "qld_address[\"convenient\"] = qld_address.apply(lambda row: is_convenient(row[\"lat\"], row[\"long\"]), axis=1)\n",
    "sa_address[\"convenient\"] = sa_address.apply(lambda row: is_convenient(row[\"lat\"], row[\"long\"]), axis=1)\n",
    "tas_address[\"convenient\"] = tas_address.apply(lambda row: is_convenient(row[\"lat\"], row[\"long\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as csv\n",
    "# nsw_address.to_csv(\"D:/UOA WORK/Summer Research/Data_Journalism_ASRS/fuel-prices/nsw_address.csv\", index=False)\n",
    "nt_address.to_csv(\"D:/UOA WORK/Summer Research/Data_Journalism_ASRS/fuel-prices/nt_address.csv\", index=False)\n",
    "qld_address.to_csv(\"D:/UOA WORK/Summer Research/Data_Journalism_ASRS/fuel-prices/qld_address.csv\", index=False)\n",
    "sa_address.to_csv(\"D:/UOA WORK/Summer Research/Data_Journalism_ASRS/fuel-prices/sa_address.csv\", index=False)\n",
    "tas_address.to_csv(\"D:/UOA WORK/Summer Research/Data_Journalism_ASRS/fuel-prices/tas_address.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
