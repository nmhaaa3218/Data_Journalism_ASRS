---
title: "Data Journalism"
author: "Manh Ha Nguyen"
date: "`r Sys.Date()`"
output: html_document
---

# Import library

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# General data wrangling and visualisation
library(tidyverse)

# Spatial analysis
library(mapview)
library(sf)
library(terra)
library(geosphere)
library(units)

# Parallel processing
library(foreach)
library(doParallel)

# Shiny app
library(shiny)

# Time series forecasting
library(forecast)
library(prophet)

# Python integration
# To find path
#   Use where python for Windows
#   Use which python3 for UNIX
library(reticulate)
use_python("C:/Users/Nebula PC/AppData/Local/Programs/Python/Python312/python.exe", required = TRUE)


```

```{python}
# Spatial analysis with OSMnx
import pandas as pd
import osmnx as ox
import time
```

# List of all function

-   Note: all function are written based on the format of nsw data structure.

## Plot gas station on map given fuel type and date

-   Ensure columns correctly named long, lat, brand, price, fueltype, collection_date
-   Need further adjustment as station may sell many fuels type

```{r}
plot_points_on_map <- function(df, fueltype, collection_date) {
  # Filter the data by fuel type
  df <- df[df$fueltype == fueltype, ]
  
  # Filter the data by collection date
  df <- df[df$collection_date == collection_date, ]
  
  # Convert lat and long to spatial points
  points_sdf = st_as_sf(df, coords = c("long", "lat"), crs = 4326)
  
  # Plot the data
  mapview(points_sdf, zcol = "price", label = points_sdf$brand)
}

```

## Average fuel type price for given postcode

-   Ensure postcode, fueltype, price correctly named

```{r}
avg_fuel_price <- function(df, fueltype, postcode) {
  # Filter the data by fuel type
  df <- df[df$fueltype == fueltype, ]
  
  # Filter the data by postcode
  df <- df[df$postcode == postcode, ]
  
  # Calculate the average price
  avg_price <- mean(df$price)
  
  # Return the average price
  return(avg_price)
}

```

## Function to extract postcode from address

```{r}
# Extract postcode from address and mutate to postcode column
postcode <- function(df) {
  df <- df %>%
    mutate(postcode = str_extract(address, "\\d{4}$"))
  return(df)
}

```

## Find closet gas station given a coordinates

-   Ensure long, lat, fueltype columns correctly named
-   Not suitable for large sets of data

```{r}
find_closest_gas_station <- function(df, fueltype, point_sdf) {
  # Filter the data by fuel type
  df <- df[df$fueltype == fueltype, ]
  
  # Convert lat and long to spatial points
  points_sdf = st_as_sf(df, coords = c("long", "lat"), crs = 4326)
  
  # Find the closest gas station
  closest_gas_station <- st_nearest_feature(point_sdf, points_sdf)
  
  # Return the closest gas station (station code)
  return(df[closest_gas_station, ])
}
```

## Combine all csv files in a folder to a single dataframe

-   Assume format of data are the same within a folder

```{r}
combine_csv <- function(path) {
  # Record start time
  start_time <- Sys.time()
  
  # Get all csv files in the folder
  files <- list.files(path = path, pattern = "*.csv", full.names = TRUE)
  
  # Combine all csv files into a single dataframe
  df <- do.call(rbind, lapply(files, read_csv))
  
  # Record end time and print time taken
  end_time <- Sys.time()
  print(end_time - start_time)
  
  # Return the dataframe
  return(df)
}

combine_csv_parallel <- function(path) {
  # Record start time
  start_time <- Sys.time()
  
  # Get all csv files in the folder
  files <- list.files(path = path, pattern = "*.csv", full.names = TRUE)
  
  # Register parallel backend
  cl <- makeCluster(detectCores())
  registerDoParallel(cl)
  
  # Combine all csv files into a single dataframe using foreach
  df <- do.call(rbind, foreach(i = files, .packages = "readr") %dopar% read_csv(i))
  
  # Stop the cluster
  stopCluster(cl)
  
  # Record end time and print time taken
  end_time <- Sys.time()
  print(end_time - start_time)
 
   # Return the dataframe
  return(df)
}


```

## Plot average price for a given fuel type by all brand over the time

```{r}
plot_avg_fuel_price_time <- function(df, fueltype) {
  
  # Filter the data for the specified fuel type
  df_fuel <- df[df$fueltype == fueltype,]
  
  # Calculate the average price per day
  df_avg <- df_fuel %>%
    group_by(collection_date) %>%
    summarise(avg_price = mean(price, na.rm = TRUE))
  
  # Create the plot
  p <- ggplot(df_avg, aes(x = collection_date, y = avg_price)) +
    geom_line() +
    geom_smooth() +
    labs(title = paste("Average Fuel Price Over Time:", fueltype),
         x = "Time",
         y = "Average Price")
  
  # Print the plot
  print(p)
}

```

## Auto rename columns

-   Rename "Longitude", "Lng" to "long"

-   Rename "Latitude", "Lat" to "lat"

-   Rename "Postcode", "POSTCODE" to "postcode"

-   Rename "FuelCode" to "fueltype"

-   Rename "Price", "PRODUCT_PRICE" to "price"

-   Rename "BrandName", "BRAND_DESCRIPTION" to "brand"

-   Rename "PUBLISH_DATE" to "collection_date"

-   

```{r}
auto_rename_columns <- function(df) {
  
  long_list <- c("Longitude", "Lng")  
  for (col_name in long_list) {
    if (col_name %in% colnames(df)) {
      df <- df %>%
        rename(long = all_of(col_name))
      break
    }
  }
  
  lat_list <- c("Latitude", "Lat")
  for (col_name in lat_list) {
    if (col_name %in% colnames(df)) {
      df <- df %>%
        rename(lat = all_of(col_name))
      break
    }
  }
  
  postcode_list <- c("Postcode", "POSTCODE")  
  for (col_name in postcode_list) {
    if (col_name %in% colnames(df)) {
      df <- df %>%
        rename(postcode = all_of(col_name))
      break
    }
  }
  
  price_list <- c("PRODUCT_PRICE", "Price")  
  for (col_name in price_list) {
    if (col_name %in% colnames(df)) {
      df <- df %>%
        rename(price = all_of(col_name))
      break
    }
  }
  
  if ("FuelCode" %in% colnames(df)) {
    df <- df %>%
      rename(fueltype = all_of("FuelCode"))
  }
  
  brand_list <- c("BrandName", "BRAND_DESCRIPTION")  
  for (col_name in brand_list) {
    if (col_name %in% colnames(df)) {
      df <- df %>%
        rename(brand = all_of(col_name))
      break
    }
  }
  
  if ("PUBLISH_DATE" %in% colnames(df)) {
    df <- df %>%
      rename(collection_date = all_of("PUBLISH_DATE"))
  }
  
  address_list <- c("Address", "ADDRESS")
  for (col_name in address_list) {
    if (col_name %in% colnames(df)) {
      df <- df %>%
        rename(address = all_of(col_name))
      break
    }
  }
  return(df)
}

```

## Selecting data given dataframe, fueltype, date and output to spatial object sf

-   Ensure state data of gas station are correctly format (fueltype, long, lat, collection_date)

```{r}
select_data <- function(data, fueltype, date) {
  # Select entries with specified fuel type
  data <- data[data$fueltype == fueltype, ]
  
  # Select entries with specified date
  data <- data[data$collection_date == date, ]
  
  # Convert to sf object
  data_sf <- st_as_sf(data, coords = c("long", "lat"), crs = 4326)
  
  return(data_sf)
}
```

## Method to calculate average distance an average person have to travel to the nearest gas station given a fuel type, date, and postcode

-   Ensure state data of gas station are correctly format (fueltype, long, lat, date, collection_date)

```{r}
calculate_distance <- function(state_fuel, postcode_sf, pop_density, fueltype, date, p_code, n_trial) {
  # Start time
  start_time <- Sys.time()
  
  # Select the postcode you are interested in
  postcode <- postcode_sf[postcode_sf$POA_CODE21 == p_code, ]

  # Generate random points
  n <- n_trial # number of points you want to generate
  random_points <- st_sample(postcode, size = n)
  # Convert to data frame for easier manipulation
  random_points_df <- as.data.frame(st_coordinates(random_points))
  # Convert to sf object
  random_points_sf <- st_as_sf(random_points_df, coords = c("X", "Y"), crs = 4326)

  # Extract population density values
  pop_density_values <- extract(pop_density, random_points_sf)

  # Add these values to your data frame
  random_points_sf$pop_density <- pop_density_values$aus_pd_2020_1km

  # Total population density in sample
  total_pop_density <- sum(random_points_sf$pop_density)

  # Divide each value by the total to get the proportion
  random_points_sf$pop_density <- random_points_sf$pop_density / total_pop_density

  # Select the fueltype you are interested in
  state_fuel_sf <- select_data(state_fuel, fueltype, date)

  # calculate nearest station for each point
  nearest_station_code <- sapply(1:n, function(i) {
    st_nearest_feature(random_points_sf[i,], state_fuel_sf)
  })

  # calculate distance between each point and its nearest station
  distance <- sapply(1:n, function(i) {
    st_distance(random_points_sf[i,], state_fuel_sf[nearest_station_code[i],])
  })

  distance <- as.data.frame(distance)
  
  # Assuming your data frame is named df
  distance$average <- cumsum(distance$distance) / seq_along(distance$distance)

  # Weighted average distance
  distance$average_weighted <- cumsum(distance$distance * random_points_sf$pop_density) / cumsum(random_points_sf$pop_density)
  
  # add spatial points to distance df (easier debug)
  distance$sf <- random_points_sf$geometry
  
  # End time
  end_time <- Sys.time()
  print(end_time - start_time)
  return(distance)
}

calculate_distance_parallel <- function(state_fuel, postcode_sf, pop_density, fueltype, date, p_code, n_trial) {
  # Start time
  start_time <- Sys.time()
  
  # Select the postcode you are interested in
  postcode <- postcode_sf[postcode_sf$POA_CODE21 == p_code, ]

  # Generate random points
  n <- n_trial # number of points you want to generate
  random_points <- st_sample(postcode, size = n)
  # Convert to data frame for easier manipulation
  random_points_df <- as.data.frame(st_coordinates(random_points))
  # Convert to sf object
  random_points_sf <- st_as_sf(random_points_df, coords = c("X", "Y"), crs = 4326)

  # Extract population density values
  pop_density_values <- extract(pop_density, random_points_sf)

  # Add these values to your data frame
  random_points_sf$pop_density <- pop_density_values$aus_pd_2020_1km

  # Total population density in sample
  total_pop_density <- sum(random_points_sf$pop_density)

  # Divide each value by the total to get the proportion
  random_points_sf$pop_density <- random_points_sf$pop_density / total_pop_density

  # Select the fueltype you are interested in
  state_fuel_sf <- select_data(state_fuel, fueltype, date)

  
  c1 <- makeCluster(detectCores())
  registerDoParallel(c1)
  # calculate nearest station for each point
  nearest_station_code <- foreach(i = 1:n, .combine = c, .packages = "sf") %dopar% {
    st_nearest_feature(random_points_sf[i,], state_fuel_sf)
  }
  stopCluster(c1)
  
  c2 <- makeCluster(detectCores())
  registerDoParallel(c2)
  # calculate distance between each point and its nearest station
  distance <- foreach(i = 1:n, .combine = c, .packages = "sf") %dopar% {
    st_distance(random_points_sf[i,], state_fuel_sf[nearest_station_code[i],])
  }
  stopCluster(c2)
  
  # Convert to data frame
  distance <- as.data.frame(distance)
  
  # Calculate average distance as n increases
  distance$average <- cumsum(distance$distance) / seq_along(distance$distance)

  # Weighted average distance
  distance$average_weighted <- cumsum(distance$distance * random_points_sf$pop_density) / cumsum(random_points_sf$pop_density)
  
  # add spatial points to distance df (easier debug)
  distance$sf <- random_points_sf$geometry
  
  # End time
  end_time <- Sys.time()
  print(end_time - start_time)
  
  return(distance)
}



```

## Calculate the average price of a given fuel in the last n days for each postcode in australia and return a data frame

```{r}
calculate_avg_postcode_fuelprice <- function(state_fuel, fueltype, n_days) {
  state_fuel <- state_fuel %>%
    filter(fueltype == fueltype) %>%
    filter(collection_date >= max(collection_date) - n_days & collection_date <= max(collection_date)) %>%
    group_by(postcode) %>%
    summarise(avg_price = mean(price, na.rm = TRUE))
  return(state_fuel)
}
```


# Import data

-   Population density from [Australia - Population Density - Humanitarian Data Exchange (humdata.org)](https://data.humdata.org/dataset/worldpop-population-density-for-australia?)

-   Postcode boundaries from [Digital boundary files \| Australian Bureau of Statistics (abs.gov.au)](https://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/digital-boundary-files)

```{r}
# fuel station and price data
nsw <- combine_csv_parallel("fuel-prices/nsw")

nt <- combine_csv_parallel("fuel-prices/nt")

qld <- combine_csv_parallel("fuel-prices/qld")

sa <- combine_csv_parallel("fuel-prices/sa")

tas <- combine_csv_parallel("fuel-prices/tas")

wa <- combine_csv_parallel("fuel-prices/wa")

# postcode boundaries
postcode_sf <- read_sf(dsn = "postcode-shapefile",layer = "POA_2021_AUST_GDA94")

# population density
pop_density <- rast("aus_pd_2020_1km.tif")

# unique state fuel station address and convenient classification
nsw_address <- read_csv("fuel-prices/nsw_address.csv", show_col_types = FALSE)

nt_address <- read_csv("fuel-prices/nt_address.csv", show_col_types = FALSE)

qld_address <- read_csv("fuel-prices/qld_address.csv", show_col_types = FALSE)

sa_address <- read_csv("fuel-prices/sa_address.csv", show_col_types = FALSE)

tas_address <- read_csv("fuel-prices/tas_address.csv", show_col_types = FALSE)

# wa_address <- read_csv("fuel-prices/wa_address.csv", show_col_types = FALSE)
```

# Data cleaning & renaming

```{r}
# Mutate postcode columns
nsw <- postcode(nsw)
tas <- postcode(tas)

# Rename columns
nt <- auto_rename_columns(nt)
qld <- auto_rename_columns(qld)
sa <- auto_rename_columns(sa)
wa <- auto_rename_columns(wa)

```

## Add long and lat for wa
### Find unique address
```{r}
unique_addresses <- wa %>%
  distinct(address, LOCATION) %>%
  select(address, LOCATION) %>%
  mutate(address = gsub("\\bRd\\b", "Road", address, ignore.case = TRUE)) %>%
  mutate(address = gsub("\\bHwy\\b", "Highway", address, ignore.case = TRUE)) %>%
  mutate(address = gsub("\\bSt\\b", "Street", address, ignore.case = TRUE)) %>%
  mutate(address = gsub("\\bDr\\b", "Drive", address, ignore.case = TRUE)) %>%
  unite("address", c("address", "LOCATION"), sep = ", ") %>%
  mutate(address = paste(address, ", Western Australia"))

# Combine with the overall unique addresses dataframe
# unique_addresses_df <- unique_addresses_df %>% bind_rows(unique_addresses)
  
  # Remove duplicate addresses
  unique_addresses_df <- unique(unique_addresses)


# unique_addresses_data <- extract_unique_addresses(wa_folder_path)


#print(unique_addresses_data)

write_csv(unique_addresses_df, "unique_addresses.csv")


```

### final file with long and lat for unique address

```{r}

df <- read.csv("output_file.csv") 

replace_address_words <- function(address) {
  address <- gsub("\\bRoad\\b", "Rd", address)
  address <- gsub("\\bDrive\\b", "Dr", address)
  address <- gsub("\\bHighway\\b", "Hwy", address)
  address <- gsub("\\bStreet\\b", "St", address)
  return(address)
}

df$ADDRESS <- sapply(df$ADDRESS, replace_address_words)

#print(df)

write.csv(df, "output_file_long_lat.csv", row.names = FALSE) 
```

### Merge lat and long for WA

```{r}

merge_with_long_lat <- function(df) {
  long_lat <- read.csv("output_file_long_lat.csv")  
  long_lat <- long_lat %>%
  select(-address)

  df <- left_join(df, long_lat, by = "ADDRESS")

  return(df)
}

wa <- merge_with_long_lat(wa)


```

# Data exploration

## All states analysis

### Calculate average price of a given fuel in the last n days for each postcode in Australia and return a data frame

-   Ideas: create a heat map to answer whether there are any patterns in price distribution of the same type of fuel in the last n days over all available postcode.

```{r}
# add price for all postcode in each states

postcode_avg_fuel_price <- calculate_avg_postcode_fuelprice(nsw, "U91", 30)

merged_data <- postcode_sf %>%
  left_join(postcode_avg_fuel_price, by = c("POA_CODE21" = "postcode"))

mapview(merged_data, zcol = "avg_price")

```

## NSW

### Map station and its price for a type of fuel across the state

For all fuel

-   further away from SYD, price tend to be higher?

-   further in land, more expensive the fuel?

-   along the coast, relatively equal?

```{r}
fueltype <- unique(nsw$fueltype)
plot_points_on_map(nsw,fueltype[1], "2023-9-23") 
```

### Fuel type vs price

-   Reccommend using EV consistently cheaper than fossil fuel
-   There exist extreme outliers for all fuel type except for EV and E85 (possible data error)

```{r}
nsw %>%
  ggplot(aes(x=fueltype,y=price)) +
  geom_boxplot() +
  labs(title="Price Distribution by Fuel Type from 2022-07-26 to 2023-11-12", x="Fuel", y="Price")
```

### Price Distribution by Brand for a type of fuel for a given day

-   Observe that even for same type of fuel and brand, there can be variations between location

```{r}
# Combustion fuel price distribution by brand
nsw %>%
  filter(fueltype != "EV") %>%   # remove EV as price is fixed
  filter(fueltype == "U91") %>%  # change fuel type
  filter(collection_date == "2023-8-21") %>%
  ggplot(aes(x=brand, y=price)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title="Price Distribution by Brand", x="Brand", y="Price")

```

### Fuel Type Popularity

-   Variations of petroleum are the most popular

```{r}
# Fuel Type Popularity
ggplot(nsw, aes(x=fueltype)) +
  geom_bar() +
  labs(title="Fuel Type Popularity", x="Fuel Type", y="Count")
```

### How far do you have to travel on average to fill up your car

-   Consider population density of each postcode to determine the weight of each postcode

-   Randomly distributed a corresponding number of representative points in each postcode

-   Distributed accordingly to the population density

-   Calculate average distance from each point to the nearest gas station

```{r}
# View the postcode shapefile
# mapview(postcode_sf, zcol = "POA_CODE21", legend = FALSE)

# plot random points on map with postcode
# plot(st_geometry(postcode))
# plot(random_points, add = TRUE, col = 'red', pch = 20)

p_code <- "2023"
n_trials <- 1000
# distance <- calculate_distance(nsw, postcode_sf, pop_density, "U91", "2023-10-10", p_code, n_trials)
distance2 <- calculate_distance_parallel(nsw, postcode_sf, pop_density, "U91", "2023-10-10", p_code, n_trials)

# Plotting the average
# ggplot(distance, aes(x = seq_along(average))) +
#  geom_line(aes(y = average), color = "blue") +
#  geom_line(aes(y = average_weighted), color = "red") +
#  labs(title = "Average distance to the closest gas station",
#       x = "n trials",
#       y = "Average distance (m)")

# Plotting the average calculated by parallel processing
ggplot(distance2, aes(x = seq_along(average))) +
  geom_line(aes(y = average), color = "blue") +
  geom_line(aes(y = average_weighted), color = "red") +
  labs(title = "Average distance to the closest gas station",
       x = "n trials",
       y = "Average distance (m)")

# print(paste("Average distance to the closest gas station in", p_code, "is", tail(distance$average, n = 1), "meters"))
# print(paste("Average weighted distance to the closest gas station in", p_code, "is", tail(distance$average_weighted, n = 1), "meters"))

print(paste("PP Average distance to the closest gas station in", p_code, "is", tail(distance2$average, n = 1), "meters"))
print(paste("PP Average weighted distance to the closest gas station in", p_code, "is", tail(distance2$average_weighted, n = 1), "meters"))

```

### Linear regression price \~ long + lat + fueltype + collection_date

-   contains influential cases that might need to ignore (might improve outcome of all assumption?)

```{r}
# linear regression to fit price ~ long lat fueltype
nsw_model_parallel <- lm(price ~ long+lat+fueltype+collection_date, data = nsw)

# Plot diagnostic
# plot(nsw_model_parallel)

# view model
summary(nsw_model_parallel)

```

### Plot average price for a given fueltype over time

```{r}
plot_avg_fuel_price_time(nsw, "U91")
```

### Time series prediction

#### Using ETS (Exponential Triple Smoothing)

-   The "frequency" is the number of observations before the seasonal pattern repeats.\
    -   Annual: 1\
    -   Quaterly: 4\
    -   Monthly: 12\
    -   Weekly: 52

```{r}
fuel_data <- nsw %>%
  filter(fueltype == "U91") %>%
  group_by(collection_date) %>%
  summarise(avg_price = mean(price, na.rm = TRUE)) #%>%
  # only take 1 year of data
  # filter(collection_date >= "2021-07-26" & collection_date <= "2023-07-26")
  
# Convert to time series object
fuel_ts <- ts(fuel_data$avg_price, frequency = 52)

# Apply stlf and forecast
model <- stlf(fuel_ts, method='ets')
fc <- forecast(model, h = 100)

# Plot the forecast
plot(fc)



```

#### Using ARIMA (Autoregressive Intergrated Moving Average)

ARIMA model is composed of three parts:

1.  **Autoregressive (AR)**: This part involves regressing the variable of interest on its own lagged (i.e., prior) values.

2.  **Integrated (I)**: This represents the differencing of raw observations to allow the time series to become stationary. In other words, it's used to remove any trend or seasonality in the data.

3.  **Moving Average (MA)**: This part involves the dependency between an observation and a residual error from a moving average model applied to lagged observations.

Each component functions as a parameter in ARIMA models, typically denoted as ARIMA(p, d, q):

-   `p`: The number of lag observations in the model, also known as the lag order.
-   `d`: The number of times the raw observations are differenced, also known as the degree of differencing.
-   `q`: The size of the moving average window, also known as the order of the moving average.

For example, an ARIMA(1,1,1) model means that it includes one lagged value of the series (p=1), differences the series once to achieve stationarity (d=1), and uses a moving average model of order 1 (q=1).

```{r}
# Convert collection_date to Date class
nsw$collection_date <- as.Date(nsw$collection_date)

# Aggregate data to daily level
daily_data <- nsw %>%
  filter(fueltype == "U91") %>%
  group_by(collection_date) %>%
  summarise(price = mean(price, na.rm = TRUE))

# Convert to time series
ts_data <- ts(daily_data$price, start = c(year(min(daily_data$collection_date)), month(min(daily_data$collection_date))), frequency = 365)

# Fit model
fit <- auto.arima(ts_data)

# Forecast
future <- forecast(fit, h = 100)

# Plot forecast
plot(future)

```

#### Using Facebook Prophet

```{r}
# Aggregate data to daily level
daily_data <- nsw %>%
  filter(fueltype == "U91") %>%
  group_by(collection_date) %>%
  summarise(price = mean(price, na.rm = TRUE)) %>%
  rename(ds = collection_date, y = price)

m <- prophet(daily_data, yearly.seasonality = TRUE, weekly.seasonality = TRUE, daily.seasonality = FALSE)
future <- make_future_dataframe(m, periods = 100)
forecast <- predict(m, future)
tail(forecast[c('ds', 'yhat', 'yhat_lower', 'yhat_upper')])
plot(m, forecast)
prophet_plot_components(m, forecast)

```

### Experimental shiny app (kinda working)

```{r}
ui <- fluidPage(
  selectInput("fueltype", "Choose a Fuel Type:", choices = unique(nsw$fueltype)),
  dateInput("collection_date", "Choose a Collection Date:", min = min(nsw$collection_date), max = max(nsw$collection_date)),
  plotOutput("map")
)

server <- function(input, output) {
  output$map <- renderPlot({
    df <- nsw[nsw$fueltype == input$fueltype, ]
    df <- df[df$collection_date == input$collection_date, ]
    points_sdf = st_as_sf(df, coords = c("long", "lat"), crs = 4326)
    mapview(points_sdf, zcol = "price", label = points_sdf$brand)
  })
}

# shinyApp(ui = ui, server = server)


```


